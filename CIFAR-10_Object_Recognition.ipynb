{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras.datasets import cifar10\n",
    "from keras.engine import Model\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = 32, 32\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "epoch = 40\n",
    "classes = 10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "y_train = np_utils.to_categorical(y_train, classes)\n",
    "y_test = np_utils.to_categorical(y_test, classes)\n",
    "\n",
    "train_samples = x_train.shape[0]\n",
    "validation_samples = x_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               1048832   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 2,786,890\n",
      "Trainable params: 2,786,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Extract the last layer from third block of vgg16 model\n",
    "#https://github.com/keras-team/keras/issues/4040\n",
    "last = base_model.get_layer('block3_pool').output\n",
    "# Add new layers on top of it\n",
    "#https://stackoverflow.com/questions/48708870/kerasunable-to-add-dense-layer-to-vgg16\n",
    "top = Flatten()(last)\n",
    "top = Dense(256, activation='relu')(top)\n",
    "top = Dropout(0.5)(top)\n",
    "pred = Dense(10, activation='sigmoid')(top)\n",
    "\n",
    "model = Model(base_model.input, pred)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-3, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_datagen.fit(x_train)\n",
    "train_generator = train_datagen.flow(x_train, y_train, batch_size=32)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "validation_generator = test_datagen.flow(x_test, y_test, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1562/1562 [==============================] - 54s 35ms/step - loss: 1.6183 - acc: 0.8992 - val_loss: 1.6118 - val_acc: 0.9000\n",
      "Epoch 2/40\n",
      "1562/1562 [==============================] - 51s 33ms/step - loss: 1.6118 - acc: 0.9000 - val_loss: 1.6118 - val_acc: 0.9000\n",
      "Epoch 3/40\n",
      "1562/1562 [==============================] - 51s 33ms/step - loss: 1.6064 - acc: 0.8994 - val_loss: 0.5080 - val_acc: 0.8947\n",
      "Epoch 4/40\n",
      "1562/1562 [==============================] - 51s 33ms/step - loss: 0.2610 - acc: 0.9055 - val_loss: 0.1956 - val_acc: 0.9247\n",
      "Epoch 5/40\n",
      "1562/1562 [==============================] - 52s 33ms/step - loss: 0.2055 - acc: 0.9214 - val_loss: 0.1638 - val_acc: 0.9365\n",
      "Epoch 6/40\n",
      "1562/1562 [==============================] - 52s 33ms/step - loss: 0.1812 - acc: 0.9304 - val_loss: 0.1466 - val_acc: 0.9420\n",
      "Epoch 7/40\n",
      "1562/1562 [==============================] - 53s 34ms/step - loss: 0.1662 - acc: 0.9365 - val_loss: 0.1356 - val_acc: 0.9473\n",
      "Epoch 8/40\n",
      "1562/1562 [==============================] - 53s 34ms/step - loss: 0.1536 - acc: 0.9413 - val_loss: 0.1296 - val_acc: 0.9496\n",
      "Epoch 9/40\n",
      "1562/1562 [==============================] - 51s 33ms/step - loss: 0.1440 - acc: 0.9452 - val_loss: 0.1222 - val_acc: 0.9525\n",
      "Epoch 10/40\n",
      "1562/1562 [==============================] - 51s 33ms/step - loss: 0.1369 - acc: 0.9479 - val_loss: 0.1224 - val_acc: 0.9516\n",
      "Epoch 11/40\n",
      "1562/1562 [==============================] - 52s 33ms/step - loss: 0.1308 - acc: 0.9503 - val_loss: 0.1179 - val_acc: 0.9536\n",
      "Epoch 12/40\n",
      "1562/1562 [==============================] - 52s 33ms/step - loss: 0.1257 - acc: 0.9521 - val_loss: 0.1092 - val_acc: 0.9571\n",
      "Epoch 13/40\n",
      "1562/1562 [==============================] - 53s 34ms/step - loss: 0.1214 - acc: 0.9539 - val_loss: 0.1050 - val_acc: 0.9591\n",
      "Epoch 14/40\n",
      "1562/1562 [==============================] - 51s 33ms/step - loss: 0.1166 - acc: 0.9556 - val_loss: 0.1003 - val_acc: 0.9613\n",
      "Epoch 15/40\n",
      "1562/1562 [==============================] - 52s 33ms/step - loss: 0.1128 - acc: 0.9570 - val_loss: 0.1001 - val_acc: 0.9610\n",
      "Epoch 16/40\n",
      "1562/1562 [==============================] - 51s 33ms/step - loss: 0.1092 - acc: 0.9586 - val_loss: 0.0986 - val_acc: 0.9622\n",
      "Epoch 17/40\n",
      "1562/1562 [==============================] - 52s 33ms/step - loss: 0.1057 - acc: 0.9598 - val_loss: 0.0954 - val_acc: 0.9632\n",
      "Epoch 18/40\n",
      "1562/1562 [==============================] - 52s 33ms/step - loss: 0.1029 - acc: 0.9609 - val_loss: 0.0968 - val_acc: 0.9627\n",
      "Epoch 19/40\n",
      "1562/1562 [==============================] - 53s 34ms/step - loss: 0.1009 - acc: 0.9616 - val_loss: 0.0952 - val_acc: 0.9633\n",
      "Epoch 20/40\n",
      "1562/1562 [==============================] - 51s 33ms/step - loss: 0.0983 - acc: 0.9629 - val_loss: 0.0907 - val_acc: 0.9650\n",
      "Epoch 21/40\n",
      "1562/1562 [==============================] - 51s 33ms/step - loss: 0.0962 - acc: 0.9636 - val_loss: 0.0862 - val_acc: 0.9669\n",
      "Epoch 22/40\n",
      "1562/1562 [==============================] - 51s 33ms/step - loss: 0.0937 - acc: 0.9647 - val_loss: 0.0902 - val_acc: 0.9655\n",
      "Epoch 23/40\n",
      "1562/1562 [==============================] - 50s 32ms/step - loss: 0.0915 - acc: 0.9652 - val_loss: 0.0889 - val_acc: 0.9659\n",
      "Epoch 24/40\n",
      "1562/1562 [==============================] - 50s 32ms/step - loss: 0.0896 - acc: 0.9662 - val_loss: 0.0874 - val_acc: 0.9665\n",
      "Epoch 25/40\n",
      "1562/1562 [==============================] - 52s 33ms/step - loss: 0.0876 - acc: 0.9670 - val_loss: 0.0817 - val_acc: 0.9686\n",
      "Epoch 26/40\n",
      "1562/1562 [==============================] - 50s 32ms/step - loss: 0.0857 - acc: 0.9673 - val_loss: 0.0829 - val_acc: 0.9681\n",
      "Epoch 27/40\n",
      "1562/1562 [==============================] - 51s 32ms/step - loss: 0.0836 - acc: 0.9685 - val_loss: 0.0818 - val_acc: 0.9687\n",
      "Epoch 28/40\n",
      "1562/1562 [==============================] - 50s 32ms/step - loss: 0.0825 - acc: 0.9691 - val_loss: 0.0838 - val_acc: 0.9686\n",
      "Epoch 29/40\n",
      "1562/1562 [==============================] - 51s 32ms/step - loss: 0.0813 - acc: 0.9691 - val_loss: 0.0824 - val_acc: 0.9684\n",
      "Epoch 30/40\n",
      "1562/1562 [==============================] - 51s 33ms/step - loss: 0.0786 - acc: 0.9704 - val_loss: 0.0847 - val_acc: 0.9678\n",
      "Epoch 31/40\n",
      "1562/1562 [==============================] - 52s 33ms/step - loss: 0.0774 - acc: 0.9707 - val_loss: 0.0837 - val_acc: 0.9682\n",
      "Epoch 32/40\n",
      "1562/1562 [==============================] - 51s 32ms/step - loss: 0.0760 - acc: 0.9715 - val_loss: 0.0799 - val_acc: 0.9697\n",
      "Epoch 33/40\n",
      "1562/1562 [==============================] - 51s 32ms/step - loss: 0.0753 - acc: 0.9717 - val_loss: 0.0747 - val_acc: 0.9714\n",
      "Epoch 34/40\n",
      "1562/1562 [==============================] - 51s 33ms/step - loss: 0.0731 - acc: 0.9721 - val_loss: 0.0764 - val_acc: 0.9709\n",
      "Epoch 35/40\n",
      "1562/1562 [==============================] - 51s 33ms/step - loss: 0.0720 - acc: 0.9728 - val_loss: 0.0796 - val_acc: 0.9697\n",
      "Epoch 36/40\n",
      "1562/1562 [==============================] - 50s 32ms/step - loss: 0.0707 - acc: 0.9736 - val_loss: 0.0763 - val_acc: 0.9712\n",
      "Epoch 37/40\n",
      "1562/1562 [==============================] - 52s 33ms/step - loss: 0.0697 - acc: 0.9739 - val_loss: 0.0798 - val_acc: 0.9703\n",
      "Epoch 38/40\n",
      "1562/1562 [==============================] - 51s 32ms/step - loss: 0.0686 - acc: 0.9742 - val_loss: 0.0747 - val_acc: 0.9718\n",
      "Epoch 39/40\n",
      "1562/1562 [==============================] - 51s 33ms/step - loss: 0.0677 - acc: 0.9746 - val_loss: 0.0746 - val_acc: 0.9714\n",
      "Epoch 40/40\n",
      "1562/1562 [==============================] - 51s 32ms/step - loss: 0.0666 - acc: 0.9751 - val_loss: 0.0759 - val_acc: 0.9718\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4ec71d57f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune the model\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=train_samples,\n",
    "    nb_epoch=epoch,\n",
    "    validation_data=validation_generator,\n",
    "    nb_val_samples=validation_samples,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.7049338786602021\n",
      "Test accuracy: 0.9541199987411499\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "model.save('weights.h5')\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
